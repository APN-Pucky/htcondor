%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Welcome to Condor}  
%
% .... or alternatively called the 'warm fuzzies' section
% <smirk>  
% 
%
% Warning: much of what you are about to read was very 
% hastily written by a very tired Todd.... Good Luck.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{Condor!user manual|(}
\index{user manual|(}
Presenting Condor \VersionNotice! Condor is developed by
the Condor Team at the University of Wisconsin-Madison (UW-Madison), and
was first installed as a production system in the UW-Madison Computer
Sciences department nearly 10 years ago. This Condor pool has since
served as a major source of computing cycles to UW faculty and students.
For many, it has revolutionized the role computing plays in their
research. An increase of one, and sometimes even two, orders of
magnitude in the computing throughput of a research organization can
have a profound impact on its size, complexity, and scope. Over the
years, the Condor Team has established collaborations with scientists
from around the world and has provided them with access to surplus
cycles (one of whom has consumed 100 CPU years!). Today, our
department's pool consists of more than 350 desktop UNIX workstations.
On a typical day, our pool delivers more than 180 CPU days to UW
researchers. Additional Condor pools have been established over the
years across our campus and the world. Groups of researchers, engineers,
and scientists have used Condor to establish compute pools ranging in
size from a handful to hundreds of workstations. We hope that Condor
will help revolutionize your compute environment as well.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{What does Condor do?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In a nutshell, Condor is a specialized batch system 
\index{batch system}
for managing
compute-intensive jobs.  Like most batch systems, Condor provides a
queueing mechanism, scheduling policy, priority scheme, and resource
classifications.  Users submit their compute jobs to Condor, Condor puts
the jobs in a queue, runs them, and then informs the user as to the
result.

Batch systems normally operate only with dedicated machines.  Often 
termed compute servers, these dedicated machines are typically owned by
one organization and dedicated to the sole purpose of running compute
jobs.  Condor can schedule jobs on dedicated machines.  But unlike traditional 
batch systems, Condor is also designed to effectively 
utilize non-dedicated machines to run jobs.  By being told to only
run compute jobs on machines which are currently not being used (no keyboard
activity, no load average, no active telnet users, etc), Condor can
effectively harness otherwise idle machines throughout a pool of machines.
This is important because often times the amount of
compute power represented by the aggregate total of all the non-dedicated 
desktop workstations sitting on people's desks throughout the
organization is far greater than the compute power of a dedicated
central resource.

Condor has several unique capabilities at its disposal which are geared 
towards effectively utilizing non-dedicated resources that are not owned or
managed by a centralized resource. These include transparent process
checkpoint and migration, remote system calls, and ClassAds.
Read section~\ref{sec:what-is-condor} for a general 
discussion of these features before reading any further.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Condor Matchmaking with ClassAds}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Before you learn about how to submit a job, it is important to
understand how Condor allocates resources. 
\index{Condor!resource allocation}
Understanding the
unique framework by which Condor matches submitted jobs with machines is
the key to getting the most from Condor's scheduling algorithm. 

Condor is unlike most other batch systems. The others typically involve
submitting a job to one of several pre-defined job queues. These
environments tend to become both constrained and complicated, as
system administrators add more queues in response to the
variety of user needs. Likewise, the user is asked to make compromises
and is given the burden of both keeping track of which queues
have which properties and deciding which queue would be the
optimal one to use.

Condor simplifies matters by acting as a matchmaker of ClassAds. Condor's
ClassAds
\index{ClassAd}
are analogous to the classified advertising section of the
newspaper. Sellers advertise specifics about what they have to sell,
hoping to attract a buyer. Buyers may advertise specifics about what
they wish to purchase. Both buyers and sellers may have constraints that
need to be satisfied. For instance, perhaps the buyer is not willing to
spend more than X dollars, and the seller requires to receive a minimum
of Y dollars. Furthermore, both want to rank requests
to their own advantage. Certainly a seller would rank
an offer  of \$50 dollars higher than a different
offer of \$25 for the same service. In Condor, users submitting
jobs can be thought of as buyers of compute resources and machine owners
are sellers. 

All machines in a Condor pool advertise their attributes,
\index{ClassAd!attributes}
such as
available RAM memory, CPU type and speed, virtual memory size, current
load average, along with other static and dynamic properties.
This machine ClassAd
\index{ClassAd!machine}
also advertises under what conditions it is
willing to run a Condor job and what type of job it would prefer. These
policy attributes can reflect the individual terms and preferences by
which all the different owners have graciously allowed their machine to
be part of the Condor pool. 
You may
advertise that your machine is only willing to run jobs at night
and when there is no keyboard activity on your machine.
In addition, you may
advertise a preference (rank) for running jobs submitted by you
or one of your co-workers. 

Likewise, when submitting a job, you specify a ClassAd with
your requirements and preferences.
The ClassAd
\index{ClassAd!job}
includes the
type of machine you  wish to use. For instance, perhaps you are
looking for the fastest floating point performance available.
You want Condor to rank available machines
based upon floating point performance. Or, perhaps you
care only that the machine has a minimum of 128 Mbytes of RAM.
Or, perhaps you will
take any machine you can get! These job attributes and requirements
are bundled up into a job ClassAd.

Condor plays the role of a matchmaker by continuously reading
all the job ClassAds and all the machine ClassAds, 
matching and ranking job ads with machine ads.
Condor makes certain that all
requirements in both ClassAds are satisfied. 

%%%%%
\subsection{Inspecting Machine ClassAds with \condor{status}}
%%%%%

\index{Condor commands!condor\_status}
Once Condor is installed,
you will get a feel for what
a machine ClassAd does by trying
the \Condor{status} command.
Try the \Condor{status} command to get
a summary of information from
ClassAds about the resources available in your pool.
Type \Condor{status} and hit enter to see a summary 
similar to the following:
\begin{center}
\begin{verbatim}
Name       Arch     OpSys        State      Activity   LoadAv Mem  ActvtyTime

adriana.cs INTEL    SOLARIS251   Claimed    Busy       1.000  64    0+01:10:00
alfred.cs. INTEL    SOLARIS251   Claimed    Busy       1.000  64    0+00:40:00
amul.cs.wi SUN4u    SOLARIS251   Owner      Idle       1.000  128   0+06:20:04
anfrom.cs. SUN4x    SOLARIS251   Claimed    Busy       1.000  32    0+05:16:22
anthrax.cs INTEL    SOLARIS251   Claimed    Busy       0.285  64    0+00:00:00
astro.cs.w INTEL    SOLARIS251   Claimed    Busy       0.949  64    0+05:30:00
aura.cs.wi SUN4u    SOLARIS251   Owner      Idle       1.043  128   0+14:40:15
\end{verbatim}
\Dots 
\end{center}


The \Condor{status} command has options that summarize machine ads 
in a variety of ways.
For example,
\begin{description}
\item[\Condor{status -available}] shows only machines which are
willing to run jobs now. 
\item[\Condor{status -run}] shows only machines
which are currently running jobs.  
\item[\Condor{status -l}] lists the machine ClassAds for all machines
in the pool.
\end{description}

Refer to the \Condor{status} command 
reference page located on page~\pageref{man-condor-status}
for a complete description of \Condor{status} command.

Figure~\ref{fig:CondorStatusL} shows the complete machine ad
\index{ClassAd!example}
\index{machine ClassAd}
for a single workstation: alfred.cs.wisc.edu. Some of the listed
attributes are used by
Condor for scheduling. Other attributes are for information purposes.
An important point is that \emph{any} of the attributes in a
machine ad can be utilized at job submission time as part of a request
or preference on what machine to use. Additional attributes
can be easily added. For example, your site administrator can
add a physical location attribute to your machine ClassAds.

%
% figures for this section
%
% condor_status -l alfred
%
\begin{center}
\begin{figure}
\CondorVerySmall
\begin{verbatim}
MyType = "Machine"
TargetType = "Job"
Name = "alfred.cs.wisc.edu"
Machine = "alfred.cs.wisc.edu"
StartdIpAddr = "<128.105.83.11:32780>"
Arch = "INTEL"
OpSys = "SOLARIS251"
UidDomain = "cs.wisc.edu"
FileSystemDomain = "cs.wisc.edu"
State = "Unclaimed"
EnteredCurrentState = 892191963
Activity = "Idle"
EnteredCurrentActivity = 892191062
VirtualMemory = 185264
Disk = 35259
KFlops = 19992
Mips = 201
LoadAvg = 0.019531
CondorLoadAvg = 0.000000
KeyboardIdle = 5124
ConsoleIdle = 27592
Cpus = 1
Memory = 64
AFSCell = "cs.wisc.edu"
START = LoadAvg - CondorLoadAvg <= 0.300000 && KeyboardIdle > 15 * 60
Requirements = TRUE
Rank = Owner == "johndoe" || Owner == "friendofjohn" 
CurrentRank =  - 1.000000
LastHeardFrom = 892191963
\end{verbatim}
\normalsize
\caption{\label{fig:CondorStatusL}Sample output from \Condor{status -l alfred}}
\end{figure}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Road-map for running jobs with Condor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The road to using Condor effectively is a short one.  The basics
are quickly and easily learned.  Unlike some other network-cluster
solutions, Condor typically does not require you to make any
changes to your program, even to do more advanced tasks such as
process checkpoint and migration. 

Using Condor can be broken down into the following steps:

\begin{description}

\item[Job Preparation.]Prepare your job for
Condor. This involves preparing it to run as a background batch job,
deciding which Condor runtime environment (or \Term{universe}) to use,
and possibly re-linking your program with the Condor library via the
\Condor{compile} command. 

\item[Submit Job to Condor.]Submit your program to Condor with
the \Condor{submit} command.
\index{Condor commands!condor\_submit}
With \Condor{submit} you tell Condor
information about the run, such as what executable to run, what
filenames to use for keyboard and screen (stdin and stdout) data,
on what type of platform to run your program, and
where to send e-mail when the job completes. You can also tell Condor how
many times to run a program; many users may want to run the same program
multiple times with multiple data sets.

\item[Condor Runs the Job.]Once submitted, monitor your job's
progress with the \Condor{q}
\index{Condor commands!condor\_q}
and \Condor{status} commands.
\index{Condor commands!condor\_status}
You may modify the order in which Condor will run your jobs with
\Condor{prio}. If desired, Condor can even inform you every time your job
is checkpointed and/or migrated to a different machine. 

\item[Job Completion.]When your program completes, Condor will tell you
(by e-mail, if preferred) the exit status of your program and various
statistics about its performances, including time used and I/O performed.
You can remove a job from the
queue prematurely with \Condor{rm}. 
\index{Condor commands!condor\_rm}

\end{description}  % of Road Map steps


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\label{sec:job-preparation}Job Preparation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Before submitting your program to Condor, you make certain
your program is batch ready.  Next, you decide upon a Condor
universe, or runtime environment, for your job.
\index{job!preparation}

%%%%%%%%%%%%%%
\subsection{A Batch Ready Program}
%%%%%%%%%%%%%%

Condor runs your program unattended and in the background. 
\index{job!batch ready}
A program that runs in the background will not be able
to do input and output in an interactive way.
Make certain
that your program will run this way before submitting it to Condor.
Condor can
redirect console output (stdout and stderr) and keyboard input (stdin)
to and from files for you.
You may have to create one or more files that contain
the proper keystrokes needed for program input.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:Choosing-Universe}
Choosing a Condor Universe}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A \Term{universe} in Condor
\index{universe}
\index{Condor!universe}
defines an execution environment. 
Condor \VersionNotice\ supports five different
universes for user jobs:
\begin{itemize}
	\item Standard
	\item Vanilla
	\item PVM
	\item MPI
	\item Globus
\end{itemize}
You state the universe to use for each job in a
submit description file when the job is submitted. 

\index{universe!standard}
The standard universe provides migration and reliability, but has some
restrictions on the programs that can be run. 
\index{universe!vanilla}
The vanilla universe provides fewer services, but has very few
restrictions.
\index{universe!PVM}
The PVM universe is for programs written to the Parallel Virtual
Machine interface.  See section~\ref{sec:PVM} for more about PVM and Condor.
\index{universe!MPI}
The MPI universe is for programs written to the MPICH interface.
See section~\ref{sec:MPI} for more about MPI and Condor.
\index{universe!Globus}
The Globus universe allows users to submit Globus jobs through the
Condor interface.  See \Url{http://www.globus.org} for more about Globus.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{\label{sec:standard-universe}Standard Universe}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{universe!standard}
In the standard universe, Condor provides \Term{checkpointing} and
\Term{remote system calls}.  These features make a job more reliable
and allow it uniform access to resources from anywhere in the pool.
To prepare a program as a standard universe job, it must be re-linked
with \Condor{compile}.  Most programs can be prepared as a standard
universe job, but there are a few restrictions.

\index{checkpoint}
\index{checkpoint image}
Condor checkpoints a job at regular intervals.
A \Term{checkpoint image} is like a snapshot of the current
state of a job.  If a job must be migrated from one machine to another,
Condor makes a checkpoint image, copies the image to the new machine,
and restarts the job \emph{right where it left off}.  If a machine should
crash or fail while it is running a job, Condor can restart the job on
a new machine from the most recent checkpoint image.  In this way, jobs
can run for months or years even in the face of occasional computer failures.

\index{remote system call}
\index{shadow}
Remote system calls make a job perceive that it is executing on its home
machine, even though it may execute on many different machines over its
lifetime.  When your job runs on a remote machine, a second process, called
a \Condor{shadow} runs on the machine where you submitted the job.
\index{condor\_shadow}
\index{agents!condor\_shadow}
\index{Condor daemon!condor\_shadow}
\index{remote system call!condor\_shadow}
Whenever your job attempts a system call, the \Condor{shadow} performs
it instead and sends the results back.  So, if your job attempts to
open a file that is stored only on the submitting machine,
the \Condor{shadow} will find it and send the data to the machine where
your job happens to be running.

To convert your program into a standard universe job, you must use
\Condor{compile} to re-link it with the Condor libraries.  Simply
put \Condor{compile} in front of your usual link command.
You do not need to modify the program's source code,
but you do need access to its un-linked object files.  A commercial
program that is packaged as a single executable file cannot be
converted into a standard universe job.

For example, if you normally link your job by executing:
\begin{verbatim}
% cc main.o tools.o -o program
\end{verbatim}

Then you can re-link your job for Condor with:
\begin{verbatim}
% condor_compile cc main.o tools.o -o program
\end{verbatim}

There are a few restrictions on standard universe jobs:

\input{user-man/limitations.tex}


%%%%%%%%%%%%
\subsubsection{Vanilla Universe}
%%%%%%%%%%%%

\index{universe!vanilla}
The vanilla universe in Condor is intended
for programs which cannot
be successfully re-linked.
Shell scripts are another case where the vanilla universe
is useful.
Unfortunately, jobs run under the vanilla universe cannot checkpoint or use
remote system calls. 
This has unfortunate consequences for a job that is partially
completed 
when the remote machine running a job must be returned
to its owner.
Condor has only two choices.  It can suspend the job, hoping to
complete it at a later time,
or it can give up and restart the job \emph{from the beginning} 
on another machine in the pool.
Jobs submitted as vanilla universe jobs must also rely on an
external mechanism 
for accessing data files from different machines
such as NFS or AFS.

%%%%%%%%%%%%
\subsubsection{Globus Universe}
%%%%%%%%%%%%

\index{universe!Globus}
The Globus universe in Condor is intended to provide the standard
Condor interface to users who wish to start Globus system jobs
from Condor. Each job queued in the job submission file is translated
into a Globus RSL string and used as the arguments to the \Prog{globusrun}
program. The manual page for \Condor{submit} has detailed descriptions for
the Globus-related attributes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Submitting a Job to Condor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{job!submitting}
A job is submitted for execution to Condor using the
\Condor{submit} command.
\index{Condor commands!condor\_submit}
\Condor{submit} takes as an argument the name of a
file called a submit description file.
\index{submit description file}
\index{file!submit description}
This file contains commands and keywords to direct the queuing of jobs.
In the submit description file, Condor finds everything it needs
to know about the job.  Items such as the name of the executable to run,
the initial working directory, and command-line arguments to the
program all go into
the submit description file.  \Condor{submit} creates a job
ClassAd based upon the information,
and Condor
works toward running the job.

The contents of a submit file
\index{submit description file!contents of}
can save time for Condor users.
It is easy to submit multiple runs of a program to
Condor. To run the same program 500 times on 500
different input data sets, arrange your data files
accordingly so that each run reads its own input, and each run
writes its own output.
Each individual run may have its own initial
working directory, stdin, stdout, stderr, command-line arguments, and
shell environment.
A program that directly opens its own
files will read the file names to use either from stdin
or from the command line. 
A program that opens a static filename every time
will need to use a separate subdirectory for the output of each run.

The \Condor{submit} manual page 
is on page~\pageref{man-condor-submit} and
contains a complete and full description of how to use \Condor{submit}.

%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:sample-submit-files}Sample submit description files}  
%%%%%%%%%%%%%%%%%%%%

In addition to the examples of submit description files given
in the 
\Condor{submit} manual page, here are a few more.
\index{submit description file!examples|(}

\subsubsection{Example 1} 

Example 1 is the simplest submit description
file possible. It queues up one copy of the program \Prog{foo} for execution
by Condor.
Since no platform is specified, Condor will use its default,
which is to run the job on a machine which has the
same architecture and operating system as the machine from which it was
submitted. 
No 
\AdAttr{input},
\AdAttr{output}, and
\AdAttr{error}
commands are given in the submit
description file, so the
files \File{stdin}, \File{stdout}, and \File{stderr} will all refer to 
\File{/dev/null}.
The program may produce output by explicitly opening a file and writing to
it.
\begin{verbatim}
  ####################                                                    
  # 
  # Example 1                                                                       
  # Simple condor job description file                                    
  #                                                                       
  ####################                                                    
                                                                          
  Executable     = foo                                                    
  Queue    
\end{verbatim}

\subsubsection{Example 2}

Example 2 queues two copies of the program \Prog{mathematica}. The
first copy will run in directory \File{run\_1}, and the second will run in
directory \File{run\_2}. For both queued copies, 
\File{stdin} will be \File{test.data},
\File{stdout} will be \File{loop.out}, and
\File{sterr} will be \File{loop.error}.
There will be two sets of files written,
as the files are each written to their own directories.
This is a convenient way to organize data if you
have a large group of Condor jobs to run. The example file 
shows program submission of
\Prog{mathematica} as a vanilla universe job.
This may be necessary if the source
and/or object code to program \Prog{mathematica} is not available.
\begin{verbatim}
  ####################     
  #                       
  # Example 2: demonstrate use of multiple     
  # directories for data organization.      
  #                                        
  ####################                    
                                         
  Executable     = mathematica          
  Universe = vanilla                   
  input   = test.data                
  output  = loop.out                
  error   = loop.error             
                                  
  Initialdir     = run_1         
  Queue                         
                               
  Initialdir     = run_2      
  Queue                     
\end{verbatim}

\subsubsection{Example 3}

The submit description file for Example 3 queues 150
\index{running multiple programs}
runs of program \Prog{foo} which has been compiled and linked for
Silicon Graphics workstations running IRIX 6.x. 
This job requires Condor to run the program on machines which have
greater than 32 megabytes of physical memory, and expresses a
preference to run the program on machines with more than 64 megabytes,
if such machines are available.  It also advises Condor that it will
use up to 28 megabytes of memory when running.
Each of the 150 runs of the program is given its own process number,
starting with process number 0.
So, files 
\File{stdin}, \File{stdout}, and \File{stderr} will
refer to \File{in.0}, \File{out.0}, and \File{err.0} for the first run
of the program,
\File{in.1}, \File{out.1},
and \File{err.1} for the second run of the program, and so forth.
A log file containing entries
about when and where Condor runs, checkpoints, and migrates processes for
the 150 queued programs
will be written into file \File{foo.log}.
\begin{verbatim}
  ####################                    
  #
  # Example 3: Show off some fancy features including
  # use of pre-defined macros and logging.
  #
  ####################                                                    

  Executable     = foo                                                    
  Requirements   = Memory >= 32 && OpSys == "IRIX6" && Arch =="SGI"     
  Rank		 = Memory >= 64
  Image_Size     = 28 Meg                                                 

  Error   = err.$(Process)                                                
  Input   = in.$(Process)                                                 
  Output  = out.$(Process)                                                
  Log = foo.log

  Queue 150
\end{verbatim}

\index{submit description file!examples|)}

%%%%%%%%%%%%%%%%%
\subsection{About Requirements and Rank}
%%%%%%%%%%%%%%%%%

The 
\AdAttr{requirements} and \AdAttr{rank} commands in the submit description file
are powerful and flexible. 
\index{requirements attribute}
\index{rank attribute}
\index{ClassAd attribute!requirements}
\index{ClassAd attribute!rank}
Using them effectively requires care, and this section presents
those details.

Both \AdAttr{requirements} and \AdAttr{rank} need to be specified 
as valid Condor ClassAd expressions.
From the \Condor{submit} manual page and the above examples, you see
that writing ClassAd expressions is intuitive, especially if you
are familiar with the programming language C.  There are some
pretty nifty expressions you can write with ClassAds.
A complete description of ClassAds and their expressions
can be found in section~\ref{classad-reference} on 
page~\pageref{classad-reference}.

All of the commands in the submit description file are case insensitive, 
\emph{except} for the ClassAd attribute string values.
ClassAds attribute names are
case insensitive, but ClassAd string
values are always \emph{case sensitive}.
The correct specification for an architecture is
\begin{verbatim}
        requirements = arch == "ALPHA"
\end{verbatim}
so an accidental specification of
\begin{verbatim}
        requirements = arch == "alpha"
\end{verbatim}
will not work due to the incorrect case.

The allowed
ClassAd attributes are those 
that appear in a machine or a job ClassAd.
To see all of the machine ClassAd attributes for all machines in
the Condor pool, run \Condor{status -l}.  
\index{Condor commands!condor\_status}
The \Arg{-l} argument to
\Condor{status} means to display all the complete machine ClassAds.
The job ClassAds, if there jobs in the queue, can be seen
with the \Condor{q -l} command.
This
will show you all the available attributes you can play with.

To help you out with what these attributes all signify,
descriptions follow for the attributes which will be common to every
machine ClassAd. Remember that because ClassAds are flexible, the
machine ads in your pool may include additional attributes specific
to your site's installation and policies. 
\subsubsection{\label{user-man-machad}ClassAd Machine Attributes}
\input{user-man/machad.tex}
\subsubsection{\label{user-man-machad}ClassAd Job Attributes}
\input{user-man/jobad.tex}



%%%%%%%%%%%% 
\subsection{Heterogeneous Submit: Submitting to a Different Architecture} 
%%%%%%%%%%%%

\index{job!heterogeneous submit}
\index{running a job!on a different architecture}
\index{heterogeneous pool!submitting a job to}
There are times when you would like to submit jobs across machine
architectures. For instance, you have an Intel machine running
LINUX. This is the machine where you do all your
work and where all your files are stored. But, perhaps the majority of
machines in your pool are Sun SPARC machines running Solaris. You
want to submit jobs directly from your LINUX box that run on the
SPARC machines.

This is easily accomplished.  You will need to create your
executable for the same type of machine where your job will run.
Condor does not convert machine instructions from one architecture
to another. 
Given the correct executable, use the
\AdAttr{requirements} command in
the submit description file to
specify the target architecture.
Without this, \Condor{submit}
\index{Condor commands!condor\_submit}
will use its default architecture, 
the type of machine you are submitting from.
An example of the\AdAttr{requirements} command is
\begin{verbatim}
  requirements = Arch == "SUN4x" && OpSys == "SOLARIS251"
\end{verbatim}
To see the architecture and operating systems of the machines
in your pool,
run \Condor{status}.

%%%%%%%%%%%% 
\subsection{Submitting to Multiple Architectures or Operating Systems} 
%%%%%%%%%%%%

\index{running a job!on multiple architectures}
\index{running a job!on multiple operating systems}
\index{heterogeneous pool!submitting a job to}

Some jobs are able to run on multiple architectures or operating
systems.  For example, a shell script may be able to run on any
machine in your pool.  Or, a SPARC binary may be able to run on either
``SUN4x'' or ``SUN4u'' machines.

You can use the 
\AdAttr{requirements} command in
the submit description file to
specify the target architectures and operating systems.
For example, if your shell script will run on either SPARC Solaris
machines or Intel LINUX machines, you can specify
\begin{verbatim}
  requirements = (Arch == "SUN4x" && OpSys == "SOLARIS26") || \
                 (Arch == "INTEL" && OpSys == "LINUX"
\end{verbatim}
Or, if your executable can run on any SPARC Solaris machine, you can
specify
\begin{verbatim}
  requirements = (Arch == "SUN4x" || Arch == "SUN4u") && \
                 (OpSys == "SOLARIS251" || OpSys == "SOLARIS26")
\end{verbatim}

Note that Condor checkpoints can not be transferred across
architectures.  Once a job has checkpointed, it must run only on
machines of the exact same architecture and operating system.  This
can be enforced with a more complex \AdAttr{requirements} expression.  For
example, if your job will run on any SPARC Solaris machine, you can
specify
\begin{verbatim}
  +CkptRequirements = ((CkptArch == Arch) || (CkptArch =?= UNDEFINED)) && \
                      ((CkptOpSys == OpSys) || (CkptOpSys =?= UNDEFINED))
  Requirements = (OpSys == "SOLARIS251" || OpSys == "SOLARIS26") && \
                 (Arch == "SUN4x" || Arch == "SUN4u") && CkptRequirements
\end{verbatim}
The \AdAttr{Requirements} expression in this example includes a
reference to a \AdAttr{CkptRequirements} expression.  The \AdAttr{CkptRequirements}
expression ensures that the job will run on a machine only if the job
has not yet checkpointed (i.e., \AdAttr{CkptArch} and \AdAttr{CkptOpSys} are both
UNDEFINED) or the machine has \AdAttr{Arch} and \AdAttr{OpSys} attributes which match
the job's \AdAttr{CkptArch} and \AdAttr{CkptOpSys} values.
This example uses the ``+'' syntax to add expressions to the Job
ClassAd.  See the \Condor{submit} manual page on
page~\pageref{man-condor-submit} for details.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Managing a Condor Job}
\input{user-man/managing.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Priorities in Condor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Condor has two independent priority controls: \Term{job}
priorities and \Term{user} priorities.  

\subsection{Job Priority}

\index{job!priority}
\index{priority!of a job}
Job priorities allow the assignment of a priority level to
each submitted Condor job in order to
control order of execution.
To set a job priority, use the \Condor{prio} command
\index{Condor commands!condor\_prio}
--- see the example in section~\ref{sec:job-prio}, or the
command reference page on page~\pageref{man-condor-prio}.
Job priorities do not impact user priorities in any fashion.
Job priorities range from -20 to +20,
with -20 being the worst and with +20 being the best.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:user-priority-explained}User priority}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{user!priority}
\index{priority!of a user}
Machines are allocated to users based upon a user's priority.
A lower numerical value for user priority means higher priority,
so a user with priority 5 will get more resources than
a user with priority 50.
User priorities in Condor can be examined with the \Condor{userprio}
command (see page~\pageref{man-condor-userprio}).
\index{Condor commands!condor\_userprio}
Condor administrators can set and change individual user priorities
with the same utility.

Condor continuously calculates the share of available machines that each
user should be allocated.    This share is inversely related to the ratio
between user priorities.
For example, a user with a priority of 10 will get twice as many
machines as a user with a priority of 20.
The priority of each individual user changes according to
the number of resources the individual is using.
Each user starts out with the best possible priority: 0.5.
If the number of machines a user currently has is greater than 
the user priority,
the user priority will worsen by numerically increasing over time.
If the number of machines is less then the priority,
the priority will improve by numerically decreasing over time. 
The long-term result is fair-share access across all users.
The speed at which Condor adjusts the priorities is
controlled with the configuration macro \Macro{PRIORITY\_HALFLIFE},
an exponential half-life value.
The default is one day.
If a user that has user priority of 100 and is
utilizing 100 machines removes all his/her jobs,
one day later that user's
priority will be 50, and two days later the priority will be 25.

Condor enforces that each user gets his/her fair share of machines
according to user priority both when allocating machines which become
available and by priority preemption of currently allocated machines.
For instance, if a low priority user is utilizing all available machines
and suddenly a higher priority user submits jobs, Condor will
immediately checkpoint and vacate jobs belonging to the lower priority
user. This will free up machines that Condor will then give over to the
higher priority user. Condor will not starve the lower priority user; it
will preempt only enough jobs so that the higher priority user's fair
share can be realized (based upon the ratio between user priorities). To
prevent thrashing of the system due to priority preemption, the Condor 
site administrator can define a \Macro{PREEMPTION\_REQUIREMENTS} expression in Condor's configuration.
The default expression that ships with Condor is configured to only preempt 
lower priority jobs that have run
for at least one hour. So in the previous example, in the worse case it
could take up to a maximum of one hour until the higher priority user
receives his fair share of machines. 

User priorities are keyed on ``username@domain'', for example
``johndoe@cs.wisc.edu''. The domain name to use, if any, is configured by
the Condor site administrator.  Thus, user priority and therefore resource
allocation is not impacted by which machine the user submits from or
even if the user submits jobs from multiple machines.

\index{nice job}
\index{priority!nice job}
An extra feature is the ability to submit a job as
a ``nice'' job (see page~\pageref{man-condor-submit-nice}).
Nice jobs artificially boost the user priority 
by one million just for the nice job.
This effectively means that nice jobs will only run on
machines that no other Condor job (that is, non-niced job) wants.
In a similar fashion, a Condor administrator could set
the user priority of any specific Condor user very high.
If done, for example, with a guest account,
the guest could only use cycles not wanted by other users of the system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{user-man/pvm.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{user-man/mpi.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{user-man/dagman.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{user-man/glidein.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\label{sec:Vacate-Explained}
About How Condor Jobs Vacate Machines}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{vacate}
When Condor needs a job to vacate a machine for whatever reason, it
sends the job an asynchronous signal specified in the \AdAttr{KillSig}
attribute of the job's classad.
The value of this attribute can be specified by
the user at submit time by placing the \Opt{kill\_sig} option in the
Condor submit description file.  

If a program wanted to do some special work when required
to vacate a machine, the program may set up a
signal handler to use a trappable signal as an indication
to clean up.
When submitting this job, this clean up signal is specified to be used with
\Opt{kill\_sig}.
Note that the clean up work needs to be quick.
If the job takes too long to go away, Condor
follows up with a SIGKILL signal which immediately terminates the
process.

\index{Condor commands!condor\_compile}
A job that is linked using \Condor{compile}
and is subsequently submitted into the standard universe, 
will checkpoint and exit upon receipt of a SIGTSTP signal.
Thus, SIGTSTP is
the default value for \AdAttr{KillSig} when submitting to the standard
universe.
The user's code may still checkpoint itself at any time
by calling one of the following functions exported by the Condor libraries:
\begin{description}
\item[\func{ckpt()}] Performs a checkpoint and then returns.
\item[\func{ckpt\_and\_exit()}] Checkpoints and exits; Condor will then
restart the process again later, potentially on a different machine.
\end{description}

For jobs submitted into the vanilla universe, the default value for
\AdAttr{KillSig} is SIGTERM,
the usual method to nicely terminate a Unix program.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Special Environment Considerations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{AFS}

\index{file system!AFS}
\index{AFS!interaction with}
The Condor daemons do not run authenticated to AFS; they do not possess
AFS tokens.
Therefore, no child process of Condor will be AFS authenticated.
The implication of this is that you must set file permissions so
that your job can access any necessary files residing on an AFS volume
without relying on having your AFS permissions.

If a job you submit to Condor needs to access files residing in AFS,
you have the following choices:
\begin{enumerate}
\item Copy the needed files from AFS to either a local hard disk where 
Condor can access them using remote system calls (if
this is a standard universe job), or copy them to an NFS volume.
\item If you must keep the files on AFS, then set a host ACL
(using the AFS \Prog{fs setacl} command) on the subdirectory to
serve as the current working directory for the job.
If a standard universe job, then the host ACL needs
to give read/write permission to any process on the submit machine.
If vanilla universe job, then you need to set the ACL such that any host 
in the pool can access the files without being authenticated.
If you do not know how to use an AFS host ACL, ask ther person at your 
site responsible for the AFS configuration.
\end{enumerate}

The Condor Team hopes to improve upon how Condor deals with AFS 
authentication in a subsequent release.

Please see section~\ref{sec:Condor-AFS-Users} on
page~\pageref{sec:Condor-AFS-Users} in the Administrators Manual for
further discussion of this problem.

\subsection{NFS Automounter}

\index{file system!NFS}
\index{NFS!interaction with}
If your current working directory when you run \Condor{submit}
\index{Condor commands!condor\_submit}
is accessed via an NFS automounter, Condor may have problems if the
automounter later decides to unmount the volume before your job has
completed.
This is because \Condor{submit} likely has stored the
dynamic mount point as the job's initial current working directory, and
this mount point could become automatically unmounted by the
automounter.

There is a simple work around: When submitting your job, use the 
\Arg{initialdir} command in your submit description file to point to
the stable access point.
For example,
suppose the NFS automounter is configured to mount a volume at mount point
\File{/a/myserver.company.com/vol1/johndoe}
whenever the directory \File{/home/johndoe} is accessed.
Adding the following line to the
submit description file solves the problem.
\begin{verbatim}
        initialdir = /home/johndoe
\end{verbatim}

\subsection{Using Globus software with Condor}
\index{universe!Globus}
\index{Globus!Interaction considerations}
Use of the Globus project software \Url{http://www.globus.org} with
Condor affects these issues:

\begin{enumerate}
\item[GSS Authentication] Is an option only in special versions of Condor,
available by request only, due to cryptographic software export controls
and Condor distribution policy.
Sites running the Condor software distributed with GSS-Authentication can 
set up their own Certification Authority (CA) by running the 
\Prog{create\_ca} script. 
Once the CA is set up, the \Condor{ca} script is used to generate 
certificates for the Condor daemons (e.g., \Condor{schedd}) and to sign
user and daemon certificates. Users can generate certificate requests
and other needed files with the \Condor{cert} program.
An X.509 certificate directory pointed to by the submit description file 
variable \Arg{x509CertDir} indicates a client program which can use GSS
authentication as a possible authentication method. Alternately, the
environment variables \Env{X509\_CERT\_DIR}, \Env{X509\_USER\_CERT},
\Env{X509\_USER\_KEY} can be used to override the default filenames and 
locations.
\Note the AUTHENTICATION\_METHOD configuration value list must contain 
the value 'GSS' for GSS authentication to be attempted.

\item[Submitting to the Globus Universe] \index{Globus!Globus universe}
\index{universe!Globus}
requires Globus version 1.1, as well as a valid Globus X.509 certificate. 
The default location for the necessary files is \$HOME/.globus, but they 
can be overridden by setting the X509\_* variables in your environment 
or the submit description file.
\Note AFS issues apply here, so you may have to copy your certificate,
trusted certificates directory, private key, and proxy to a local
filesystem disk.

\item[\Condor{glidein}] \index {Globus!\Condor{glidein}} requires a valid 
Globus X.509 certificate, and the PATH to the \Prog{globusrun} program 
must be in your environment.
\Note to allow a globus resource to join your Condor pool, your 
administrator must add the hostname(s) to the HOSTALLOW\_WRITE and
HOSTALLOW\_READ configuration values.
\end{enumerate}

\subsection{Condor Daemons That Do Not Run as root}

\index{UNIX daemon!running as root}
\index{daemon!running as root}
Condor is normally installed such that the Condor daemons have root
permission.
This allows Condor to run the \condor{shadow} 
\index{Condor daemon!condor\_shadow}
\index{remote system call!condor\_shadow}
process and
your job with your UID and file access rights.
When Condor
is started as root, your Condor jobs can access whatever files you can.

However, it is possible that whomever installed Condor 
did not have root access, or
decided not to run the daemons as root.
That is unfortunate,
since Condor is designed to be run as the Unix user root.
To see if Condor is
running as root on a specific machine, enter the command
\begin{verbatim}
        condor\_status -master -l <machine-name>
\end{verbatim}

where \verb@machine-name@ is the name of the specified machine.
This command displays a \condor{master} ClassAd; if the
attribute \AdAttr{RealUid} equals zero,
then the Condor daemons are indeed
running with root access.  If the
\AdAttr{RealUid} attribute is not zero, then the Condor daemons do not have
root access.

\Note The UNIX program \Prog{ps}
is \emph{not} an effective
method of determining if Condor is running with root access.
When using \Prog{ps},
it may often appear that the daemons are
running as the condor user instead of root.
However, note that the \Prog{ps},
command shows the current \emph{effective} owner of the
process, not the \emph{real} owner.  (See the \Cmd{getuid}{2} and
\Cmd{geteuid}{2} Unix man pages for details.)  In Unix, a process
running under the real UID of root may switch its effective UID.
(See the \Cmd{seteuid}{2} man page.)
For security reasons, the daemons
only set the effective uid to root when absolutely necessary
(to perform a privileged operation).

If they are not running with root access, you need to make any/all files
and/or directories that your job will touch readable and/or writable by
the UID (user id) specified by the RealUid attribute.
Often this may
mean using the Unix command \verb@chmod 777@
on the directory where you submit your Condor job.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Potential Problems}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Renaming of argv[0]}

\index{argv[0]!Condor use of}
When Condor starts up your job, it renames argv[0] (which usually
contains the name of the program) to \condor{exec}.
This is
convenient when examining a machine's processes with the UNIX
command \Prog{ps}; the process
is easily identified as a Condor job.  

Unfortunately, some programs read argv[0] expecting their own program
name and get confused if they find something unexpected like
\condor{exec}.

\index{Condor!user manual|)}
\index{user manual|)}
